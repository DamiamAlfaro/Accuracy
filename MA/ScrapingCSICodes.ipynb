{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkqQYqoCUmwczK61Uw50E6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DamiamAlfaro/Sonder/blob/main/MA/ScrapingCSICodes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "zeIkIngEHwU-"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import openpyxl\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.abc.org/Membership/MasterFormat-CSI-Codes-NAICS-Codes/CSI-Codes\"\n",
        "\n",
        "response = requests.get(url)\n",
        "html_content = response.content\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "sectionNumber = soup.find_all('a',class_=\"numCase\")\n",
        "sectionTitle = soup.find_all('a',class_=\"CSIdescr\")\n",
        "\n",
        "sectionNumbers = [sectionNumber[i].text for i in range(len(sectionNumber))]\n",
        "sectionTitles = [sectionTitle[i].text for i in range(len(sectionTitle))]\n",
        "\n",
        "print(sectionNumbers)\n",
        "print(sectionTitles)"
      ],
      "metadata": {
        "id": "yEmEvB0JpNpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "!pip install selenium\n",
        "!pip install beautifulsoup4\n",
        "!apt-get update  # To update ubuntu to correctly run apt install\n",
        "!apt-get install -y chromium-chromedriver xvfb\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install pyvirtualdisplay\n",
        "\"\"\"\n",
        "from pyvirtualdisplay import Display\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Set up the virtual display\n",
        "display = Display(visible=0, size=(1024, 768))\n",
        "display.start()\n",
        "\n",
        "# Set up Chrome options\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--disable-gpu')\n",
        "chrome_options.add_argument('--remote-debugging-port=9222')\n",
        "\n",
        "# Initialize the WebDriver with options\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "text = []\n",
        "try:\n",
        "    # Open the initial webpage\n",
        "    url = 'https://www.abc.org/Membership/MasterFormat-CSI-Codes-NAICS-Codes/CSI-Codes'  # Replace with the actual URL\n",
        "    driver.get(url)\n",
        "\n",
        "    # Find the specific <a> tag by its id and click it\n",
        "    link = driver.find_element(By.ID, 'dnn_ctr66648_View_rptLevel1_LinkButton1_0')\n",
        "    link.click()\n",
        "\n",
        "    # Wait for the new page to load (adjust the wait time as necessary)\n",
        "    time.sleep(5)\n",
        "\n",
        "    # Scrape the text from the new page\n",
        "    new_page_content = driver.page_source\n",
        "    soup = BeautifulSoup(new_page_content, 'html.parser')\n",
        "\n",
        "    # Extract specific elements if needed\n",
        "    desired_text = soup.get_text(strip=True)  # Modify this to target specific elements if needed\n",
        "    text.append(desired_text.split(\"(www.crosswalk.biz)\"))\n",
        "finally:\n",
        "    # Close the WebDriver\n",
        "    driver.quit()\n",
        "    # Stop the virtual display\n",
        "    display.stop()\n",
        "\n",
        "newText = text[0][1].split(\"Associated Builders and Contractors\")\n",
        "print(newText[0])"
      ],
      "metadata": {
        "id": "1a10G2_bqU0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f9VshATwvNH5"
      }
    }
  ]
}